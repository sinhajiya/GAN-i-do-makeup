{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4270361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\nir\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\anaconda3\\envs\\nir\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\nir\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to C:\\Users\\JIYA SINHA/.cache\\torch\\hub\\checkpoints\\vgg19-dcbb9e9d.pth\n"
     ]
    },
    {
     "ename": "RemoteDisconnected",
     "evalue": "Remote end closed connection without response",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRemoteDisconnected\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 88\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;66;03m# Losses\u001b[39;00m\n\u001b[32m     87\u001b[39m adv_loss = LSGAN().to(device)\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m vgg_loss = \u001b[43mVGGLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.to(device)\n\u001b[32m     89\u001b[39m make_up_loss = MakeUpLoss().to(device)\n\u001b[32m     90\u001b[39m cycle_loss = CycleConsistencyLoss().to(device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\codes\\GAN-i-do-makeup\\losses.py:57\u001b[39m, in \u001b[36mVGGLoss.__init__\u001b[39m\u001b[34m(self, vgg_normal_correct)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28mself\u001b[39m.vgg_normal_correct = vgg_normal_correct\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m vgg_normal_correct:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28mself\u001b[39m.vgg = \u001b[43mVGG19_feature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvgg_normal_correct\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     59\u001b[39m     \u001b[38;5;28mself\u001b[39m.vgg = VGG19_feature()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\codes\\GAN-i-do-makeup\\losses.py:82\u001b[39m, in \u001b[36mVGG19_feature.__init__\u001b[39m\u001b[34m(self, vgg_normal_correct)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, vgg_normal_correct=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m     81\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     vgg_pretrained = \u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvgg19\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m.features\n\u001b[32m     83\u001b[39m     \u001b[38;5;28mself\u001b[39m.vgg_slices = nn.ModuleList([\n\u001b[32m     84\u001b[39m         vgg_pretrained[:\u001b[32m2\u001b[39m],   \u001b[38;5;66;03m# r11\u001b[39;00m\n\u001b[32m     85\u001b[39m         vgg_pretrained[\u001b[32m2\u001b[39m:\u001b[32m7\u001b[39m],  \u001b[38;5;66;03m# r21\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     88\u001b[39m         vgg_pretrained[\u001b[32m21\u001b[39m:\u001b[32m30\u001b[39m] \u001b[38;5;66;03m# r51\u001b[39;00m\n\u001b[32m     89\u001b[39m     ])\n\u001b[32m     90\u001b[39m     \u001b[38;5;28mself\u001b[39m.mean = torch.Tensor([\u001b[32m0.485\u001b[39m, \u001b[32m0.456\u001b[39m, \u001b[32m0.406\u001b[39m]).view(\u001b[32m1\u001b[39m,\u001b[32m3\u001b[39m,\u001b[32m1\u001b[39m,\u001b[32m1\u001b[39m).cuda()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\nir\\Lib\\site-packages\\torchvision\\models\\_utils.py:142\u001b[39m, in \u001b[36mkwonly_to_pos_or_kw.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    135\u001b[39m     warnings.warn(\n\u001b[32m    136\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msequence_to_str(\u001b[38;5;28mtuple\u001b[39m(keyword_only_kwargs.keys()),\u001b[38;5;250m \u001b[39mseparate_last=\u001b[33m'\u001b[39m\u001b[33mand \u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m as positional \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    137\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    138\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minstead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    139\u001b[39m     )\n\u001b[32m    140\u001b[39m     kwargs.update(keyword_only_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\nir\\Lib\\site-packages\\torchvision\\models\\_utils.py:228\u001b[39m, in \u001b[36mhandle_legacy_interface.<locals>.outer_wrapper.<locals>.inner_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    225\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[pretrained_param]\n\u001b[32m    226\u001b[39m     kwargs[weights_param] = default_weights_arg\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuilder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\nir\\Lib\\site-packages\\torchvision\\models\\vgg.py:485\u001b[39m, in \u001b[36mvgg19\u001b[39m\u001b[34m(weights, progress, **kwargs)\u001b[39m\n\u001b[32m    465\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"VGG-19 from `Very Deep Convolutional Networks for Large-Scale Image Recognition <https://arxiv.org/abs/1409.1556>`__.\u001b[39;00m\n\u001b[32m    466\u001b[39m \n\u001b[32m    467\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    481\u001b[39m \u001b[33;03m    :members:\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    483\u001b[39m weights = VGG19_Weights.verify(weights)\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_vgg\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mE\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\nir\\Lib\\site-packages\\torchvision\\models\\vgg.py:105\u001b[39m, in \u001b[36m_vgg\u001b[39m\u001b[34m(cfg, batch_norm, weights, progress, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m model = VGG(make_layers(cfgs[cfg], batch_norm=batch_norm), **kwargs)\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     model.load_state_dict(\u001b[43mweights\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\nir\\Lib\\site-packages\\torchvision\\models\\_api.py:90\u001b[39m, in \u001b[36mWeightsEnum.get_state_dict\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_state_dict\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> Mapping[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_state_dict_from_url\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\nir\\Lib\\site-packages\\torch\\hub.py:867\u001b[39m, in \u001b[36mload_state_dict_from_url\u001b[39m\u001b[34m(url, model_dir, map_location, progress, check_hash, file_name, weights_only)\u001b[39m\n\u001b[32m    865\u001b[39m         r = HASH_REGEX.search(filename)  \u001b[38;5;66;03m# r is Optional[Match[str]]\u001b[39;00m\n\u001b[32m    866\u001b[39m         hash_prefix = r.group(\u001b[32m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m867\u001b[39m     \u001b[43mdownload_url_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcached_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhash_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_legacy_zip_format(cached_file):\n\u001b[32m    870\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_zip_load(cached_file, model_dir, map_location, weights_only)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\nir\\Lib\\site-packages\\torch\\hub.py:708\u001b[39m, in \u001b[36mdownload_url_to_file\u001b[39m\u001b[34m(url, dst, hash_prefix, progress)\u001b[39m\n\u001b[32m    706\u001b[39m file_size = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    707\u001b[39m req = Request(url, headers={\u001b[33m\"\u001b[39m\u001b[33mUser-Agent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mtorch.hub\u001b[39m\u001b[33m\"\u001b[39m})\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m u = \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m meta = u.info()\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(meta, \u001b[33m\"\u001b[39m\u001b[33mgetheaders\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\nir\\Lib\\urllib\\request.py:216\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    215\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\nir\\Lib\\urllib\\request.py:519\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    516\u001b[39m     req = meth(req)\n\u001b[32m    518\u001b[39m sys.audit(\u001b[33m'\u001b[39m\u001b[33murllib.Request\u001b[39m\u001b[33m'\u001b[39m, req.full_url, req.data, req.headers, req.get_method())\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[32m    522\u001b[39m meth_name = protocol+\u001b[33m\"\u001b[39m\u001b[33m_response\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\nir\\Lib\\urllib\\request.py:536\u001b[39m, in \u001b[36mOpenerDirector._open\u001b[39m\u001b[34m(self, req, data)\u001b[39m\n\u001b[32m    533\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    535\u001b[39m protocol = req.type\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m                          \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m_open\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[32m    539\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\nir\\Lib\\urllib\\request.py:496\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    495\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    497\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    498\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\nir\\Lib\\urllib\\request.py:1391\u001b[39m, in \u001b[36mHTTPSHandler.https_open\u001b[39m\u001b[34m(self, req)\u001b[39m\n\u001b[32m   1390\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[32m-> \u001b[39m\u001b[32m1391\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\nir\\Lib\\urllib\\request.py:1352\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1350\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[32m   1351\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[32m-> \u001b[39m\u001b[32m1352\u001b[39m     r = \u001b[43mh\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1353\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1354\u001b[39m     h.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\nir\\Lib\\http\\client.py:1395\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1393\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1394\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1395\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1396\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1397\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\nir\\Lib\\http\\client.py:325\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    327\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\nir\\Lib\\http\\client.py:294\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    290\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mreply:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mrepr\u001b[39m(line))\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line:\n\u001b[32m    292\u001b[39m     \u001b[38;5;66;03m# Presumably, the server closed the connection before\u001b[39;00m\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# sending a valid response.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RemoteDisconnected(\u001b[33m\"\u001b[39m\u001b[33mRemote end closed connection without\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    295\u001b[39m                              \u001b[33m\"\u001b[39m\u001b[33m response\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    297\u001b[39m     version, status, reason = line.split(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[32m2\u001b[39m)\n",
      "\u001b[31mRemoteDisconnected\u001b[39m: Remote end closed connection without response"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "from dataset import MTDataset\n",
    "from generator import Generator\n",
    "from discriminators import MultiscaleDiscriminator, NLayerDiscriminator\n",
    "from losses import LSGAN, VGGLoss, MakeUpLoss, CycleConsistencyLoss\n",
    "\n",
    "exp_name = 'try1'\n",
    "save_dir = os.path.join('./checkpoints', exp_name)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Configs\n",
    "A_dir = './data/no_makeup'\n",
    "B_dir = './data/makeup'\n",
    "A_seg_dir = './data/no_makeup_segs'\n",
    "B_seg_dir = './data/makeup_segs'\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 1\n",
    "lr = 2e-4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "alpha = 1\n",
    "beta = 10\n",
    "gamma = 0.005\n",
    "lambda_lips = 1\n",
    "lambda_skin = 1\n",
    "lambda_face = 0.1\n",
    "cycle_loss_metric = 'l1'\n",
    "disc = 'patchgan'\n",
    "csv_dataroot=r'E:\\codes\\GAN-i-do-makeup\\splits'\n",
    "image_dataroot=r\"E:\\datasets\\MT\\all\"\n",
    "phase='train'\n",
    "\n",
    "# Save training config\n",
    "config_str = f\"\"\"Training Configuration:\n",
    "-----------------------\n",
    "A_dir: {A_dir}\n",
    "B_dir: {B_dir}\n",
    "A_seg_dir: {A_seg_dir}\n",
    "B_seg_dir: {B_seg_dir}\n",
    "save_dir: {save_dir}\n",
    "csv_dataroot: {csv_dataroot}\n",
    "image_dataroot: {image_dataroot}\n",
    "phase: Train\n",
    "epochs: {epochs}\n",
    "batch_size: {batch_size}\n",
    "learning_rate: {lr}\n",
    "device: {device}\n",
    "discriminator: {disc}\n",
    "cycle_loss_metric: {cycle_loss_metric}\n",
    "\n",
    "Loss Weights:\n",
    "alpha (GAN loss): {alpha}\n",
    "beta (Cycle consistency): {beta}\n",
    "gamma (Perceptual/VGG): {gamma}\n",
    "lambda_lips: {lambda_lips}\n",
    "lambda_skin: {lambda_skin}\n",
    "lambda_face: {lambda_face}\n",
    "\"\"\"\n",
    "\n",
    "with open(os.path.join(save_dir, 'training_config.txt'), 'w') as f:\n",
    "    f.write(config_str)\n",
    "\n",
    "# Dataset\n",
    "dataset = MTDataset(csv_dataroot, image_dataroot, phase)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# Models\n",
    "netG = Generator().to(device)\n",
    "if disc == 'patchgan':\n",
    "    netDA = NLayerDiscriminator().to(device)\n",
    "    netDB = NLayerDiscriminator().to(device)\n",
    "elif disc == 'MSD':\n",
    "    netDA = MultiscaleDiscriminator().to(device)\n",
    "    netDB = MultiscaleDiscriminator().to(device)\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(netG.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_DA = torch.optim.Adam(netDA.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_DB = torch.optim.Adam(netDB.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "# Losses\n",
    "adv_loss = LSGAN().to(device)\n",
    "vgg_loss = VGGLoss().to(device)\n",
    "make_up_loss = MakeUpLoss().to(device)\n",
    "cycle_loss = CycleConsistencyLoss().to(device)\n",
    "\n",
    "# Training\n",
    "for epoch in range(epochs):\n",
    "    for i, data in enumerate(dataloader):\n",
    "        real_no_makeup = data['non_makeup'].to(device)\n",
    "        real_makeup = data['makeup'].to(device)\n",
    "\n",
    "        # Generator forward\n",
    "        gen1 = netG(no_makeup=real_no_makeup, makeup=real_makeup)\n",
    "        gen1_no_makeup = gen1['No_makeup_output']\n",
    "        gen1_makeup = gen1['makeup_output']\n",
    "        \n",
    "        gen2 = netG(no_makeup=gen1_no_makeup, makeup=gen1_makeup)\n",
    "        gen2_no_makeup = gen2['No_makeup_output']\n",
    "        gen2_makeup = gen2['makeup_output']\n",
    "        \n",
    "        # Discriminator A forward\n",
    "        loss_DA_real = adv_loss(netDA(real_no_makeup), True)\n",
    "        loss_DA_fake = adv_loss(netDA(gen1_no_makeup.detach()), False)\n",
    "        loss_DA = (loss_DA_real + loss_DA_fake) * 0.5\n",
    "\n",
    "        # Discriminator B forward\n",
    "        loss_DB_real = adv_loss(netDB(real_makeup), True)\n",
    "        loss_DB_fake = adv_loss(netDB(gen1_makeup.detach()), False)\n",
    "        loss_DB = (loss_DB_real + loss_DB_fake) * 0.5\n",
    "\n",
    "        optimizer_DA.zero_grad()\n",
    "        loss_DA.backward()\n",
    "        optimizer_DA.step()\n",
    "\n",
    "        optimizer_DB.zero_grad()\n",
    "        loss_DB.backward()\n",
    "        optimizer_DB.step()\n",
    "\n",
    "        L_adv = loss_DA + loss_DB\n",
    "        L_per = vgg_loss(gen_non_makeup=gen1_no_makeup, non_makeup=real_no_makeup, gen_makeup=gen1_makeup, makeup=real_makeup)\n",
    "        L_cycle = cycle_loss(rec_non_makeup = gen2_no_makeup, non_makeup=real_no_makeup, rec_makeup=gen2_makeup, makeup=real_makeup)\n",
    "        L_makeup = make_up_loss(gen_makeup=gen1_makeup, real_makeup=real_makeup)\n",
    "\n",
    "        loss = alpha * L_adv + beta * L_cycle + gamma * L_per + L_makeup\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f\"[{epoch}/{epochs}] [{i}/{len(dataloader)}] \"\n",
    "                  f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        save_path = os.path.join(save_dir, f'netG_epoch{epoch}.pth')\n",
    "        torch.save(netG.state_dict(), save_path)\n",
    "        print(f\"Checkpoint saved to {save_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
