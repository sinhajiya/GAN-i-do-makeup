{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4270361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "from dataset import MTDataset\n",
    "from generator import Generator\n",
    "from discriminators import MultiscaleDiscriminator, NLayerDiscriminator\n",
    "from losses import LSGAN, VGGLoss, MakeUpLoss, CycleConsistencyLoss\n",
    "\n",
    "exp_name = 'try1'\n",
    "save_dir = os.path.join('./checkpoints', exp_name)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Configs\n",
    "A_dir = './data/no_makeup'\n",
    "B_dir = './data/makeup'\n",
    "A_seg_dir = './data/no_makeup_segs'\n",
    "B_seg_dir = './data/makeup_segs'\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 1\n",
    "lr = 2e-4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "alpha = 1\n",
    "beta = 10\n",
    "gamma = 0.005\n",
    "lambda_lips = 1\n",
    "lambda_skin = 1\n",
    "lambda_face = 0.1\n",
    "cycle_loss_metric = 'l1'\n",
    "disc = 'patchgan'\n",
    "csv_dataroot=r'E:\\codes\\GAN-i-do-makeup\\splits'\n",
    "image_dataroot=r\"E:\\datasets\\MT\\all\"\n",
    "phase='train'\n",
    "\n",
    "# Save training config\n",
    "config_str = f\"\"\"Training Configuration:\n",
    "-----------------------\n",
    "A_dir: {A_dir}\n",
    "B_dir: {B_dir}\n",
    "A_seg_dir: {A_seg_dir}\n",
    "B_seg_dir: {B_seg_dir}\n",
    "save_dir: {save_dir}\n",
    "csv_dataroot: {csv_dataroot}\n",
    "image_dataroot: {image_dataroot}\n",
    "phase: Train\n",
    "epochs: {epochs}\n",
    "batch_size: {batch_size}\n",
    "learning_rate: {lr}\n",
    "device: {device}\n",
    "discriminator: {disc}\n",
    "cycle_loss_metric: {cycle_loss_metric}\n",
    "\n",
    "Loss Weights:\n",
    "alpha (GAN loss): {alpha}\n",
    "beta (Cycle consistency): {beta}\n",
    "gamma (Perceptual/VGG): {gamma}\n",
    "lambda_lips: {lambda_lips}\n",
    "lambda_skin: {lambda_skin}\n",
    "lambda_face: {lambda_face}\n",
    "\"\"\"\n",
    "\n",
    "with open(os.path.join(save_dir, 'training_config.txt'), 'w') as f:\n",
    "    f.write(config_str)\n",
    "\n",
    "# Dataset\n",
    "dataset = MTDataset(csv_dataroot, image_dataroot, phase)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# Models\n",
    "netG = Generator().to(device)\n",
    "if disc == 'patchgan':\n",
    "    netDA = NLayerDiscriminator().to(device)\n",
    "    netDB = NLayerDiscriminator().to(device)\n",
    "elif disc == 'MSD':\n",
    "    netDA = MultiscaleDiscriminator().to(device)\n",
    "    netDB = MultiscaleDiscriminator().to(device)\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(netG.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_DA = torch.optim.Adam(netDA.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_DB = torch.optim.Adam(netDB.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "# Losses\n",
    "adv_loss = LSGAN().to(device)\n",
    "vgg_loss = VGGLoss().to(device)\n",
    "make_up_loss = MakeUpLoss().to(device)\n",
    "cycle_loss = CycleConsistencyLoss().to(device)\n",
    "\n",
    "# Training\n",
    "for epoch in range(epochs):\n",
    "    for i, data in enumerate(dataloader):\n",
    "        real_no_makeup = data['non_makeup'].to(device)\n",
    "        real_makeup = data['makeup'].to(device)\n",
    "\n",
    "        # Generator forward\n",
    "        gen1 = netG(no_makeup=real_no_makeup, makeup=real_makeup)\n",
    "        gen1_no_makeup = gen1['No_makeup_output']\n",
    "        gen1_makeup = gen1['makeup_output']\n",
    "        \n",
    "        gen2 = netG(no_makeup=gen1_no_makeup, makeup=gen1_makeup)\n",
    "        gen2_no_makeup = gen2['No_makeup_output']\n",
    "        gen2_makeup = gen2['makeup_output']\n",
    "        \n",
    "        # Discriminator A forward\n",
    "        loss_DA_real = adv_loss(netDA(real_no_makeup), True)\n",
    "        loss_DA_fake = adv_loss(netDA(gen1_no_makeup.detach()), False)\n",
    "        loss_DA = (loss_DA_real + loss_DA_fake) * 0.5\n",
    "\n",
    "        # Discriminator B forward\n",
    "        loss_DB_real = adv_loss(netDB(real_makeup), True)\n",
    "        loss_DB_fake = adv_loss(netDB(gen1_makeup.detach()), False)\n",
    "        loss_DB = (loss_DB_real + loss_DB_fake) * 0.5\n",
    "\n",
    "        optimizer_DA.zero_grad()\n",
    "        loss_DA.backward()\n",
    "        optimizer_DA.step()\n",
    "\n",
    "        optimizer_DB.zero_grad()\n",
    "        loss_DB.backward()\n",
    "        optimizer_DB.step()\n",
    "\n",
    "        L_adv = loss_DA + loss_DB\n",
    "        L_per = vgg_loss(gen_non_makeup=gen1_no_makeup, non_makeup=real_no_makeup, gen_makeup=gen1_makeup, makeup=real_makeup)\n",
    "        L_cycle = cycle_loss(rec_non_makeup = gen2_no_makeup, non_makeup=real_no_makeup, rec_makeup=gen2_makeup, makeup=real_makeup)\n",
    "        L_makeup = make_up_loss(gen_makeup=gen1_makeup, real_makeup=real_makeup)\n",
    "\n",
    "        loss = alpha * L_adv + beta * L_cycle + gamma * L_per + L_makeup\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f\"[{epoch}/{epochs}] [{i}/{len(dataloader)}] \"\n",
    "                  f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        save_path = os.path.join(save_dir, f'netG_epoch{epoch}.pth')\n",
    "        torch.save(netG.state_dict(), save_path)\n",
    "        print(f\"Checkpoint saved to {save_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
